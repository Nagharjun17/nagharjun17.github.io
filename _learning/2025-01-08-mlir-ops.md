---
layout: default
title: "MLIR - Adding Max and Square ReLU operations to the Toy dialect and Lowering to LLVM"
year: 2025
stack: "C++ • MLIR • LLVM"
excerpt: "Learning by adding new operations to an existing dialect and lowering it down to LLVM."
tags: [MLIR, LLVM]
image: assets/img/projects/mlirllvm.png
---

{% if page.image %}
<figure>
  <img src="{{ page.image | relative_url }}" alt="{{ page.title }} screenshot" loading="lazy">
  <figcaption>{{ page.title }}</figcaption>
</figure>
{% endif %}

**YOU CAN REPLICATE THIS PROJECT -> https://github.com/Nagharjun17/MLIRX**

* Added custom MLIR dialect ops SquareReLU and Max to the Toy Ch6 example (ODS, builders, Dialect integration).
* Implemented lowering: MaxOp → Affine loops (CmpF, Select) and SquareReLU → Mul + Max.
* Extended MLIRGen + CMake to support new ops and regenerate code.
* Validated full pipeline by building with Ninja and emitting LLVM IR via toyc-ch6 -emit=llvm.

[GitHub Repo](https://github.com/Nagharjun17/MLIRX)

<div style="margin-top: 2rem;">
  <a href="/learning" style="text-decoration: none; font-weight: bold;">← Back</a>
</div>
